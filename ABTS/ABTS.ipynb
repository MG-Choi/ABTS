{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "# from tqdm import tqdmㅇ\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "from shapely.geometry import Point\n",
    "from pyproj import Geod\n",
    "\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "# 경고 메시지 무시 설정\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABTS Simulation code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Trip Occurence Builder\n",
    "### 1.1. The probability of a person with age ‘a’ having ‘t’ trips occurs in a single day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_prob_with_day(df, age_col, tripPurpose_col, travday_col):\n",
    "    \"\"\"\n",
    "    Calculate the probability of trip purpose by age group and day type (Weekday or Weekend) using Naive Bayes.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the NHTS data\n",
    "    - age_col: The name of the column representing age groups\n",
    "    - tripPurpose_col: The name of the column representing the trip purpose\n",
    "    - travday_col: The name of the column representing the day type (Weekday or Weekend)\n",
    "\n",
    "    Returns:\n",
    "    - result_df: A DataFrame with the calculated probabilities for each combination of age group, trip purpose, and day type\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a DataFrame to store the results\n",
    "    result_df = pd.DataFrame(columns=['Age', 'Trip_pur', 'Day_Type', 'Prob'])\n",
    "\n",
    "    # Extract unique values of each Age group, Trip type, and define day types\n",
    "    unique_ages = df[age_col].unique()\n",
    "    unique_trips = df[tripPurpose_col].unique()\n",
    "    day_types = ['Weekday', 'Weekend']\n",
    "    \n",
    "    # Total Population\n",
    "    total_pop = len(df)\n",
    "\n",
    "    # Loop over each Age group\n",
    "    for age in unique_ages:\n",
    "        age_group_pop = len(df[df[age_col] == age])\n",
    "        \n",
    "        # Calculate P(X_a / X) - Probability of being in age group 'a' in the total population\n",
    "        p_xa_x = age_group_pop / total_pop\n",
    "        \n",
    "        # Loop over each Trip type\n",
    "        for trip in unique_trips:\n",
    "            \n",
    "            # Also, loop over each Day Type (Weekday, Weekend)\n",
    "            for day_type in day_types:\n",
    "                \n",
    "                # Subset DataFrame based on day type\n",
    "                if day_type == 'Weekday':\n",
    "                    sub_df = df[df[travday_col] == 'Weekday']\n",
    "                else:  # For Weekend\n",
    "                    sub_df = df[df[travday_col] == 'Weekend']\n",
    "                \n",
    "                # Calculate P(θ_t / θ) - Probability of trip type 't' given the day type\n",
    "                total_trips = sub_df[tripPurpose_col].value_counts().sum()\n",
    "                p_theta_t_theta = sub_df[sub_df[tripPurpose_col] == trip].shape[0] / total_trips\n",
    "                \n",
    "                # Calculate P(X_a | θ_t) - Probability of being in age group 'a' given the trip type 't'\n",
    "                p_xa_thetat = len(sub_df[(sub_df[age_col] == age) & (sub_df[tripPurpose_col] == trip)]) / sub_df[sub_df[tripPurpose_col] == trip].shape[0]\n",
    "                \n",
    "                # Calculate Naive Bayes probability\n",
    "                prob = (p_xa_thetat * p_theta_t_theta) / p_xa_x\n",
    "                \n",
    "                # Setting the result column name based on the day type\n",
    "                col_name = 'WD_prob' if day_type == 'Weekday' else 'WK_prob'\n",
    "                \n",
    "                # Add the result to the DataFrame using concat\n",
    "                temp_df = pd.DataFrame([{'Age': age, 'Trip_pur': trip, 'Day_Type': day_type, 'Prob': prob}])\n",
    "                result_df = pd.concat([result_df, temp_df], ignore_index=True)\n",
    "                \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. The number of trips occurring ‘k’ times for a single individual ‘i’ in a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trip_distribution(trippub_total, id_age, id_col, day_type_col, trip_purpose_col):\n",
    "    \"\"\"\n",
    "    Generate a distribution of trips based on unique IDs, age, day type, and trip purpose.\n",
    "\n",
    "    Parameters:\n",
    "    - trippub_total: DataFrame containing trip data (NHTS)\n",
    "    - id_age: The name of the column representing the age identifier\n",
    "    - id_col: The name of the column representing unique identifiers for individuals or entities\n",
    "    - day_type_col: The name of the column representing the type of the day (e.g., Weekday or Weekend)\n",
    "    - trip_purpose_col: The name of the column representing the purpose of the trip\n",
    "\n",
    "    Returns:\n",
    "    - count_series: A DataFrame that shows the count of trips for each combination of ID, age, day type, and trip purpose.\n",
    "    \"\"\"\n",
    "\n",
    "    # Copy the input DataFrame to avoid modifying the original data\n",
    "    trip_total = trippub_total.copy()\n",
    "    \n",
    "    # Remove rows where the sum of DWELTIME for each combination of PERSONID_new and TRAVDAY_new is 0\n",
    "    sum_dweltime = trip_total.groupby(['uniqID', 'Day_Type'])['Dwell_T_min'].sum().reset_index()\n",
    "    valid_ids = sum_dweltime[sum_dweltime['Dwell_T_min'] != 0][['uniqID', 'Day_Type']]\n",
    "    trip_total = pd.merge(trip_total, valid_ids, on=['uniqID', 'Day_Type'])\n",
    "\n",
    "    # Aggregate the count of rows\n",
    "    count_series = trip_total.groupby([id_col, id_age, day_type_col, trip_purpose_col]).size().reset_index(name='count')\n",
    "    \n",
    "    # The following line is commented out as it seems redundant given that 'day_type_col' already specifies day type\n",
    "    # count_series['TRAVDAY_new'] = count_series[day_type_col].apply(lambda x: 'Weekday' if x == 'Weekday' else 'Weekend')\n",
    "    \n",
    "    return count_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combined_trip_count(naive_prob, trip_count, age_n_dict, method, Home_cbg, W_k_weekday=1.0, W_k_weekend=1.0,\n",
    "                                 W_t_weekday=None, W_t_weekend=None, print_progress=True):\n",
    "    \"\"\"\n",
    "    Generate a combined trip count distribution based on age groups, day type, and trip purpose.\n",
    "    \n",
    "    Parameters:\n",
    "    - naive_prob: DataFrame containing Naive Bayes probabilities.\n",
    "    - trip_count: DataFrame with trip count data.\n",
    "    - age_n_dict: Dictionary mapping age groups to the number of individuals.\n",
    "    - method: String specifying the method to distribute trips ('multinomial' or 'cdf').\n",
    "    - Home_cbg: The home census block group id.\n",
    "    - W_k_weekday: Weight multiplier for trip counts on weekdays.\n",
    "    - W_k_weekend: Weight multiplier for trip counts on weekends.\n",
    "    - W_t_weekday: Dictionary with trip purpose as keys and weights as values for weekdays.\n",
    "    - W_t_weekend: Dictionary with trip purpose as keys and weights as values for weekends.\n",
    "    - print_progress: Boolean flag to print progress.\n",
    "    \n",
    "    Returns:\n",
    "    - combined_result_df: DataFrame with the generated trip distribution.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Print initial message if progress printing is enabled\n",
    "    if print_progress:\n",
    "        print('<Trip occurrence builder>')\n",
    "    \n",
    "    # Initialize weight dictionaries if not provided\n",
    "    if W_t_weekday is None:\n",
    "        W_t_weekday = {}  # Default weekday weights as empty dict\n",
    "    if W_t_weekend is None:\n",
    "        W_t_weekend = {}  # Default weekend weights as empty dict\n",
    "        \n",
    "    \n",
    "    # Create an empty DataFrame to store results\n",
    "    combined_result_df = pd.DataFrame()\n",
    "\n",
    "    # Define extended day types to include specific days of the week\n",
    "    extended_day_types = {\n",
    "        'Weekday': ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday'],\n",
    "        'Weekend': ['Saturday', 'Sunday']\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Define a nested function to generate trip counts for each age group and day type\n",
    "    def generate_trip_count(naive_result_total, trip_count, age_group, n, method, extended_day_types, start_id=0):\n",
    "        result_list = []  # Initialize an empty list to store intermediate results\n",
    "\n",
    "        # Iterate over each base day type and its actual days\n",
    "        for base_day_type, actual_days in extended_day_types.items():\n",
    "            # Filter trip counts for the current age group and base day type\n",
    "            trip_count_df = trip_count[(trip_count['age_class'] == age_group) & (trip_count['Day_Type'] == base_day_type)]\n",
    "            # Aggregate trip counts by person\n",
    "            trip_count_by_person = trip_count_df.groupby(['uniqID']).agg({'count': 'sum'}).reset_index()\n",
    "\n",
    "\n",
    "            # Filter Naive Bayes probabilities for the current age group and base day type\n",
    "            prob_df = naive_result_total[(naive_result_total['Age'] == age_group) & (naive_result_total['Day_Type'] == base_day_type)]\n",
    "\n",
    "            # Iterate over each actual day\n",
    "            for actual_day in actual_days:\n",
    "                # Repeat process 'n' times for simulation\n",
    "                for i in range(n):\n",
    "                    current_id = start_id + i  # Unique identifier for each simulation iteration\n",
    "                    \n",
    "                    # Determine trip count multiplier based on day type\n",
    "                    if actual_day in ['Sunday', 'Saturday']:  # Weekend\n",
    "                        theta_i = np.random.choice(trip_count_by_person['count']) * W_k_weekend\n",
    "                    else:  # Weekday\n",
    "                        theta_i = np.random.choice(trip_count_by_person['count']) * W_k_weekday\n",
    "                    \n",
    "                    # Adjust probabilities with weights if they exist for the trip purpose\n",
    "                    adjusted_prob_df = prob_df.copy()\n",
    "                    \n",
    "                    if actual_day == 'Sunday' or actual_day == 'Saturday': # weekend\n",
    "                        for trip_purpose, weight in W_t_weekday.items():\n",
    "                            adjusted_prob_df.loc[adjusted_prob_df['Trip_pur'] == trip_purpose, 'Prob'] *= weight\n",
    "                    else:\n",
    "                        for trip_purpose, weight in W_t_weekend.items():\n",
    "                            adjusted_prob_df.loc[adjusted_prob_df['Trip_pur'] == trip_purpose, 'Prob'] *= weight\n",
    "\n",
    "                    # Normalize probabilities again after weighting\n",
    "                    adjusted_prob_df['Prob'] /= adjusted_prob_df['Prob'].sum()\n",
    "\n",
    "                    if method == 'multinomial':\n",
    "                        trips = np.random.multinomial(theta_i, adjusted_prob_df['Prob'])\n",
    "                    elif method == 'cdf':\n",
    "                        cdf = np.cumsum(adjusted_prob_df['Prob'])\n",
    "                        trips = np.histogram(np.random.rand(theta_i), bins=[0] + list(cdf), range=(0,1))[0]\n",
    "                    \n",
    "                    \n",
    "                    home_count = trips[prob_df['Trip_pur'] == 'Home'][0]\n",
    "                    \n",
    "                    # Append results for each trip purpose\n",
    "                    for t, count in zip(prob_df['Trip_pur'], trips):\n",
    "                        result_list.append({'uniqID': current_id, 'ageGroup': age_group, 'Day_Type': actual_day, 'Week_Type': base_day_type, 'TRPPURP': t, 'count': count})\n",
    "\n",
    "        # Convert the list of results into a DataFrame\n",
    "        result_df = pd.DataFrame(result_list)\n",
    "        return result_df\n",
    "\n",
    "    # Initialize the starting unique ID for simulation\n",
    "    current_max_id = 0\n",
    "\n",
    "    # Decide whether to use tqdm for progress indication based on the print_progress flag\n",
    "    iterator = tqdm(age_n_dict.items(), desc='1. Processing age groups to generate trip counts') if print_progress else age_n_dict.items()\n",
    "\n",
    "    # Iterate over each age group and its associated number of individuals\n",
    "    for age_group, n in iterator:\n",
    "        temp_df = generate_trip_count(naive_prob, trip_count, age_group, n, method, extended_day_types, current_max_id)\n",
    "        combined_result_df = pd.concat([combined_result_df, temp_df], ignore_index=True)\n",
    "        current_max_id += n  # Update the current_max_id for the next batch\n",
    "\n",
    "    if print_progress:\n",
    "        tqdm.pandas(desc=\"2. Adjust home counts\")\n",
    "    \n",
    "    # Function to adjust home count in each group\n",
    "    def adjust_home_count(group):\n",
    "        total_count = group['count'].sum()\n",
    "        home_count_row = group[group['TRPPURP'] == 'Home']\n",
    "\n",
    "        # Ensure that there are at least 2 home counts if total count is 2 or more\n",
    "        if total_count >= 2 and home_count_row['count'].iloc[0] < 2:\n",
    "            group.loc[group['TRPPURP'] == 'Home', 'count'] = 2\n",
    "        return group\n",
    "\n",
    "    # Apply the function to adjust home counts\n",
    "    if print_progress:\n",
    "        combined_result_df = combined_result_df.groupby(['uniqID', 'Day_Type']).progress_apply(adjust_home_count).reset_index(drop=True)\n",
    "    else:\n",
    "        combined_result_df = combined_result_df.groupby(['uniqID', 'Day_Type']).apply(adjust_home_count).reset_index(drop=True)\n",
    "\n",
    "    # Assign the Home_cbg to all rows\n",
    "    combined_result_df[\"Home_cbg\"] = Home_cbg\n",
    "    \n",
    "    # columns: Wt amd Wk\n",
    "    \n",
    "    \n",
    "    # Function to retrieve weight for a given trip purpose from the weight dictionaries\n",
    "    def get_weight(trppurp, W_t):\n",
    "        return W_t.get(trppurp, 1.0)  # Return 1.0 if the trip purpose is not in the dictionary\n",
    "\n",
    "    # Assign weekday and weekend trip count weights to all rows\n",
    "    combined_result_df['Wk_wD'] = W_k_weekday\n",
    "    combined_result_df['Wk_wK'] = W_k_weekend\n",
    "\n",
    "    # Apply the get_weight function to assign trip purpose weights for weekdays and weekends\n",
    "    combined_result_df['Wt_wD'] = combined_result_df['TRPPURP'].apply(lambda x: get_weight(x, W_t_weekday))\n",
    "    combined_result_df['Wt_wK'] = combined_result_df['TRPPURP'].apply(lambda x: get_weight(x, W_t_weekend))\n",
    "\n",
    "    return combined_result_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Trip Chains Builder\n",
    "### 2.0. preprocessing: Create trip seqeunce using origin NHTS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trip_sequence(df, print_progress=True):\n",
    "    \"\"\"\n",
    "    Creates a trip sequence column by concatenating Trip_pur values for each group defined by age_class, Day_Type, and uniqID.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing trip data (NHTS).\n",
    "    - print_progress: Boolean indicating whether to print progress information.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with an added column 'Trip_sequence' representing the sequence of trip purposes.\n",
    "    \"\"\"\n",
    "\n",
    "    # Function to aggregate counts after trip sequence generation\n",
    "    def aggregate_count(df):\n",
    "        # Group by relevant columns and aggregate 'count' values\n",
    "        aggregated_df = df.groupby(['age_class', 'Day_Type', 'uniqID', 'Trip_sequence']).agg({'count': 'sum'}).reset_index()\n",
    "        return aggregated_df\n",
    "    \n",
    "    # Sort the DataFrame by start time to ensure trip sequence is chronological\n",
    "    sorted_df = df.sort_values('sta_T_hms')\n",
    "    \n",
    "    # Group the sorted DataFrame by age class, day type, and unique ID\n",
    "    grouped = sorted_df.groupby(['age_class', 'Day_Type', 'uniqID'])\n",
    "    \n",
    "    # Initialize a list to store result data\n",
    "    result_data = []\n",
    "    \n",
    "#     print(\"create trip sequence...\")\n",
    "\n",
    "    # Check if progress should be printed, wrap the iterator with tqdm if true\n",
    "    iterator = tqdm(grouped, desc='Creating trip sequences derived from data...') if print_progress else grouped\n",
    "\n",
    "    # Iterate through each group\n",
    "    for name, group in iterator:\n",
    "        # Concatenate the 'Trip_pur' values to form the trip sequence\n",
    "        trip_sequence = '-'.join(group['Trip_pur'])\n",
    "        # Append the result as a dictionary to the result_data list\n",
    "        result_data.append({\n",
    "            'age_class': name[0],\n",
    "            'Day_Type': name[1],\n",
    "            'uniqID': name[2],\n",
    "            'Trip_sequence': trip_sequence,\n",
    "            # Set initial count to 1 for each unique sequence\n",
    "            'count': 1\n",
    "        })\n",
    "    \n",
    "    # Convert the result_data list to a DataFrame\n",
    "    result_df = pd.DataFrame(result_data)\n",
    "    \n",
    "    # Aggregate counts in case there are duplicate sequences\n",
    "    result_df = aggregate_count(result_df)\n",
    "    \n",
    "    # Return the final DataFrame with aggregated trip sequences\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Finding optimal origin sequence O_i most similar to S_i\n",
    "### 2.2) Randomly assign the trip sequence for S_i\n",
    "### 2.3) Reassign the sequence of trip in S_i based on O_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTripSequence(trip_sequence_simul, trip_sequence_origin, print_progress=True):\n",
    "    \"\"\"\n",
    "    Constructs and refines trip sequences for simulated data to ensure realistic patterns by aligning them with sequences from original NHTS data. \n",
    "    The process includes adjusting 'Home' trip counts to reflect real-world patterns, duplicating rows based on trip counts, \n",
    "    finding and assigning the most similar trip sequence from NHTS data, and sequentially refining trip sequences to eliminate inconsistencies \n",
    "    such as duplicated or consecutive 'Home' trips and ensuring all trip sequences start and end with 'Home'. \n",
    "    The function applies several passes of adjustments to achieve coherent and logically ordered trip sequences that realistically simulate daily travel behavior.\n",
    "\n",
    "    Parameters:\n",
    "    - trip_sequence_simul: DataFrame containing simulated trip data that needs sequence construction and adjustment.\n",
    "    - trip_sequence_origin: DataFrame with original trip sequences from NHTS data, used as a reference for similarity comparison.\n",
    "    - print_progress: Boolean flag indicating whether to print progress messages and bars during the execution.\n",
    "\n",
    "    Returns:\n",
    "    - A DataFrame with refined trip sequences for each individual and day, ready for further analysis or simulation tasks.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Print initial message if progress printing is enabled\n",
    "    if print_progress:\n",
    "        print('<Trip chain builder>')\n",
    "    \n",
    "    # Adjust home count in the simulated trip sequences to match real trip patterns\n",
    "    tqdm.pandas(desc=\"1. Split trips purpose to each row\")\n",
    "    def adjust_home_count(group):\n",
    "        # Calculate the sum of non-home trip counts and adjust home count accordingly\n",
    "        non_home_count_sum = group.loc[group['TRPPURP'] != 'Home', 'count'].sum()\n",
    "        new_home_count = non_home_count_sum + 1\n",
    "\n",
    "        # Adjust the home count in the DataFrame\n",
    "        home_idx = group.loc[group['TRPPURP'] == 'Home'].index\n",
    "        if len(home_idx) > 0:  # If there is a home trip\n",
    "            home_idx = home_idx[0]\n",
    "            if group.at[home_idx, 'count'] > new_home_count:\n",
    "                group.at[home_idx, 'count'] = new_home_count\n",
    "            group = group[group['count'] > 0]\n",
    "\n",
    "        # Duplicate rows based on the 'count' value to create individual trip records\n",
    "        new_rows = []\n",
    "        for _, row in group.iterrows():\n",
    "            new_rows.extend([row] * int(row['count']))  # Duplicate row 'count' times\n",
    "        new_group = pd.DataFrame(new_rows).reset_index(drop=True)\n",
    "        new_group['count'] = 1  # Reset count to 1 for all rows\n",
    "\n",
    "        return new_group\n",
    "\n",
    "    # Apply adjust_home_count function to each group\n",
    "    if print_progress == True:\n",
    "        adjusted_simul_df = trip_sequence_simul.groupby(['Day_Type', 'uniqID']).progress_apply(adjust_home_count).reset_index(drop=True)\n",
    "    else:\n",
    "        adjusted_simul_df = trip_sequence_simul.groupby(['Day_Type', 'uniqID']).apply(adjust_home_count).reset_index(drop=True)\n",
    "#     --------------------#\n",
    "    \n",
    "    tqdm.pandas(desc=\"2. Find similar sequence from NHTS data\") \n",
    "    \n",
    "    def find_most_similar_sequence(query_seq, available_seqs): #1. find trip sequence in origin NHTS, similar to the simulated trips\n",
    "        \n",
    "        max_similarity = 0\n",
    "        most_similar = None\n",
    "\n",
    "        for seq in available_seqs:\n",
    "            \n",
    "            similarity = sum(x == y for x, y in zip(query_seq, seq)) # Calculate string similarity\n",
    "            if similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "                most_similar = seq\n",
    "\n",
    "        return most_similar\n",
    "\n",
    "    \n",
    "    unique_trip_seqs = trip_sequence_origin['Trip_sequence'].unique()\n",
    "    \n",
    "    def get_sequence(group):\n",
    "        # Assign the most similar trip sequence from NHTS data to each group\n",
    "        if len(group) == 1:\n",
    "            group['seq_similar_orig'] = 1\n",
    "            return group\n",
    "\n",
    "        query_seq = \"-\".join(group['TRPPURP'].tolist())\n",
    "#         print(query_seq)\n",
    "        \n",
    "        # 가장 비슷한 sequence 찾기\n",
    "        most_similar_seq = find_most_similar_sequence(query_seq, unique_trip_seqs)\n",
    "        group['seq_similar_orig'] = most_similar_seq\n",
    "        return group\n",
    "\n",
    "    # Apply get_sequence function to each group\n",
    "    if print_progress == True:\n",
    "        df_with_seq = adjusted_simul_df.groupby(['uniqID', 'ageGroup', 'Day_Type']).progress_apply(get_sequence).reset_index(drop=True)\n",
    "    else:\n",
    "        df_with_seq = adjusted_simul_df.groupby(['uniqID', 'ageGroup', 'Day_Type']).apply(get_sequence).reset_index(drop=True)\n",
    "    \n",
    "\n",
    "    def MakeSequence(df): \n",
    "        # This function constructs trip sequences for individuals based on their simulated trip purposes and the most similar trip sequence from the original data.\n",
    "\n",
    "        # Initialize an empty column for the sequence\n",
    "        df['sequence'] = None\n",
    "\n",
    "        # Define an iterator for grouping by unique IDs and Day_Type, to process each individual's trips per day\n",
    "        iterator = tqdm(df.groupby(['uniqID', 'Day_Type']), desc='3. Assign trip sequence to individuals') if print_progress else df.groupby(['uniqID', 'Day_Type'])\n",
    "    \n",
    "        for name, group in iterator:\n",
    "        # If the group size is 1, it implies there's only a single trip purpose, simplifying the sequence assignment\n",
    "            if  group['seq_similar_orig'].iloc[0] == 1:\n",
    "#                 group['sequence'].iloc[0] = 1\n",
    "                \n",
    "                df.loc[group.index, 'sequence'] = 1\n",
    "            else:\n",
    "                seq_similar_orig = group['seq_similar_orig'].iloc[0].split('-')\n",
    "                n = len(group)\n",
    "                sequence = []\n",
    "\n",
    "                # Count 'Home' trips and assign them to the first and last sequence positions\n",
    "                home_count = group['TRPPURP'].value_counts().get('Home', 0) \n",
    "                home_assigned = 0\n",
    "                for trppurp in group['TRPPURP']:\n",
    "                    if trppurp == 'Home':\n",
    "                        home_assigned += 1\n",
    "                        sequence.append(1 if home_assigned == 1 else n)   # Ensure 'Home' appears first and last in the sequence.\n",
    "\n",
    "                # Process remaining trip purposes not assigned as 'Home'\n",
    "                remaining = [trppurp for trppurp in group['TRPPURP'] if trppurp != 'Home']\n",
    "#                 print(seq_similar_orig)\n",
    "                remaining_indices = sorted(set(range(2, n)) - set(sequence))\n",
    "\n",
    "#                 display(group)             \n",
    "                \n",
    "                for trppurp in remaining: # Initially assign a random sequence to remaining trip purposes\n",
    "                    random_seq = random.choice(remaining_indices)\n",
    "                    remaining_indices.remove(random_seq)\n",
    "                    sequence.append(random_seq)\n",
    "\n",
    "                    \n",
    "                for idx in range(1, len(seq_similar_orig)): # Reassign sequence numbers based on the original sequence to maintain trip order\n",
    "                    prev_purpose, current_purpose = seq_similar_orig[idx-1], seq_similar_orig[idx]\n",
    "\n",
    "                    # prev_purpose의 sequence를 찾고, 그 다음 sequence를 current_purpose에 할당\n",
    "                    for seq_num, purp in sorted(list(enumerate(sequence)), key=lambda x: x[1]):\n",
    "                        if purp == prev_purpose:\n",
    "                            next_seq = seq_num + 1\n",
    "                            if next_seq in sequence:\n",
    "                                continue  # Skip if already assigned\n",
    "\n",
    "                            # Find and set the next sequence number for current trip purpose based on its predecessor\n",
    "                            for cur_seq_num, cur_purp in sorted(list(enumerate(sequence)), key=lambda x: x[1]):\n",
    "                                if cur_purp == current_purpose:\n",
    "                                    sequence[cur_seq_num] = next_seq\n",
    "                                    break\n",
    "\n",
    "                            break  # Stop after reassigning the current purpose   \n",
    "                \n",
    "                # Update the DataFrame with the newly assigned sequences\n",
    "                df.loc[group.index, 'sequence'] = sequence\n",
    "\n",
    "        return df\n",
    "    \n",
    "    df_with_seq = MakeSequence(df_with_seq)\n",
    "    \n",
    "\n",
    "    #-------------------------\n",
    "    \n",
    "    def print_4():\n",
    "        for i in tqdm(range(1), desc = '4. Organize and arrange tables'):\n",
    "        # This loop does nothing but show progress. It's a visual indicator and does not perform any data manipulation.\n",
    "            None\n",
    "    \n",
    "    if print_progress == True:\n",
    "        print_4()\n",
    "    \n",
    "    #---------------\n",
    "    \n",
    "    def removeDuplHome(df): \n",
    "        # This function removes duplicated 'Home' trip purposes that occur consecutively in the trip sequence, except for the first and last instance.\n",
    "        # It ensures that each trip sequence correctly reflects a realistic pattern of leaving from and returning to home at most once during the trip sequence.\n",
    "\n",
    "        \n",
    "        # Iterate through each group based on 'uniqID' and 'Day_Type'\n",
    "        iterator = tqdm(df.groupby(['uniqID', 'Day_Type']), desc = ' - 4.1. remove duplicated Home trip') if print_progress else df.groupby(['uniqID', 'Day_Type'])\n",
    "        \n",
    "        for name, group in iterator:\n",
    "\n",
    "            if len(group) == 1:\n",
    "                continue\n",
    "            # Calculate the number of 'Home' occurrences in seq_similar_orig\n",
    "            seq_similar_orig_count = group['seq_similar_orig'].iloc[0].split('-').count('Home') - 2  # Exclude first and last\n",
    "            if seq_similar_orig_count < 0:\n",
    "                seq_similar_orig_count = 0\n",
    "\n",
    "            # Get the count of 'Home' in the group\n",
    "            home_count = group['TRPPURP'].value_counts().get('Home', 0)\n",
    "\n",
    "            # Calculate how many 'Home' entries to remove, excluding the first and last\n",
    "            home_to_remove = home_count - 2 - seq_similar_orig_count\n",
    "\n",
    "            # Remove excess 'Home' occurrences\n",
    "            if home_to_remove > 0:\n",
    "                index_to_remove = group[group['TRPPURP'] == 'Home'].index[1:-1][:home_to_remove]\n",
    "                df.drop(index_to_remove, inplace=True)   \n",
    "\n",
    "        return df\n",
    "    \n",
    "    df_removed_dupl_Home = removeDuplHome(df_with_seq)\n",
    "    \n",
    "    \n",
    "    def setHomeSequence(df): \n",
    "        # Adjusts the sequence of 'Home' trips for each group of trips by a unique individual on a specific day. \n",
    "        # If there are exactly two 'Home' entries, their sequences are set to 1 and the last sequence number, ensuring that trips start and end at 'Home'.\n",
    "        \n",
    "        # Iterate through each group based on 'uniqID' and 'Day_Type'\n",
    "        iterator = tqdm(df.groupby(['uniqID', 'Day_Type']), desc = ' - 4.2. reassign Home trip sequence') if print_progress else df.groupby(['uniqID', 'Day_Type'])\n",
    "        \n",
    "        for name, group in iterator:\n",
    "\n",
    "            # If there are exactly 2 'Home' entries, set their sequence to 1 and the total number of rows in the group\n",
    "            if group['TRPPURP'].value_counts().get('Home', 0) == 2:\n",
    "                home_indices = group[group['TRPPURP'] == 'Home'].index.tolist()\n",
    "                # Set the sequence of the first 'Home' entry to 1\n",
    "                df.loc[home_indices[0], 'sequence'] = 1\n",
    "                \n",
    "                # Set the sequence of the second 'Home' entry to the length of the group, making it the last trip\n",
    "                df.loc[home_indices[1], 'sequence'] = len(group)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    df_setHome = setHomeSequence(df_removed_dupl_Home)\n",
    "    \n",
    "    \n",
    "    def reassignMiddleHomeSequences(df):\n",
    "        # For trip sequences with more than two 'Home' entries, this function reassigns the sequences of middle 'Home' entries.\n",
    "        # The aim is to distribute these 'Home' trips more realistically within the sequence, avoiding consecutive 'Home' trips and ensuring that they are placed appropriately among other trip purposes.\n",
    "\n",
    "        # Iterate through each group based on 'uniqID' and 'Day_Type'\n",
    "        iterator = tqdm(df.groupby(['uniqID', 'Day_Type']), desc = ' - 4.3. Reassign Home trips if more than 3 trips') if print_progress else df.groupby(['uniqID', 'Day_Type'])\n",
    "        \n",
    "        for name, group in iterator:\n",
    "\n",
    "            # If there are more than 2 'Home' entries\n",
    "            if group['TRPPURP'].value_counts().get('Home', 0) > 2:\n",
    "\n",
    "                # Get the index for all 'Home' entries\n",
    "                home_indices = group[group['TRPPURP'] == 'Home'].index.tolist()\n",
    "\n",
    "                # Exclude the first and the last 'Home' entries\n",
    "                middle_home_indices = home_indices[1:-1]\n",
    "\n",
    "                # Calculate the range for random sequence values\n",
    "                last_sequence = group['sequence'].max()\n",
    "                possible_sequences = list(range(3, last_sequence - 1)) #\n",
    "\n",
    "                if len(possible_sequences) < len(middle_home_indices):\n",
    "                    # If there are not enough possible sequence numbers, remove excess rows\n",
    "                    df.drop(middle_home_indices[len(possible_sequences):], inplace=True)\n",
    "                    middle_home_indices = middle_home_indices[:len(possible_sequences)]\n",
    "\n",
    "                random.shuffle(possible_sequences)\n",
    "\n",
    "                # Assign random sequence values to the middle 'Home' entries\n",
    "                for i, index in enumerate(middle_home_indices):\n",
    "                    df.loc[index, 'sequence'] = possible_sequences[i]\n",
    "\n",
    "        return df\n",
    "\n",
    "    # Example usage\n",
    "    df_with_middle_home_reassigned = reassignMiddleHomeSequences(df_setHome)\n",
    "\n",
    "    def reassignConsecutiveSequences(df, num): \n",
    "        # Reassigns sequences to ensure they are consecutive without any duplicates or gaps, especially after prior adjustments might have created irregularities in the sequence numbering.\n",
    "\n",
    "        # Iterate through each group based on 'uniqID' and 'Day_Type'        \n",
    "        iterator = tqdm(df.groupby(['uniqID', 'Day_Type']), desc = ' - 4.' + str(num+3) + '. Reassign consecutive numbers of sequence_' + str(num)) if print_progress else df.groupby(['uniqID', 'Day_Type'])\n",
    "        \n",
    "        for name, group in iterator:\n",
    "\n",
    "            # Sort by sequence\n",
    "            sorted_group = group.sort_values('sequence')\n",
    "            new_sequence = 1\n",
    "            prev_sequence = None\n",
    "\n",
    "            for index, row in sorted_group.iterrows():\n",
    "                # If current sequence is same as previous, increment for non-'Home' or drop 'Home'\n",
    "                if row['sequence'] == prev_sequence:\n",
    "                    if row['TRPPURP'] == 'Home':\n",
    "                        # If the TRPPURP is 'Home', remove the row\n",
    "                        df.drop(index, inplace=True)\n",
    "                    else:\n",
    "                        # If the TRPPURP is not 'Home', increment the sequence by 1\n",
    "                        new_sequence += 1\n",
    "\n",
    "                df.loc[index, 'sequence'] = new_sequence\n",
    "                prev_sequence = row['sequence']\n",
    "                new_sequence += 1\n",
    "\n",
    "        return df\n",
    "\n",
    "    \n",
    "    df_with_consecutive_sequences = reassignConsecutiveSequences(df_with_middle_home_reassigned, 1)\n",
    "    df_with_consecutive_sequences = reassignConsecutiveSequences(df_with_consecutive_sequences, 2)\n",
    "\n",
    "    # sort and reorganize -----------------\n",
    "\n",
    "    \n",
    "    # rename column: 'seq_similar_orig' -> seq_NHTS\n",
    "    df_with_consecutive_sequences.rename(columns={'seq_similar_orig': 'seq_NHTS'}, inplace=True)\n",
    "\n",
    "    columns = ['uniqID', 'ageGroup', 'Home_cbg', 'Day_Type', 'Week_Type', 'TRPPURP', 'sequence', 'seq_NHTS']\n",
    "    \n",
    "    # ALl columns of df_with_consecutive_sequences DataFrame\n",
    "    all_columns = df_with_consecutive_sequences.columns.tolist()\n",
    "\n",
    "    # Extract all the columns except selected column\n",
    "    remaining_columns = [col for col in all_columns if col not in columns]\n",
    "\n",
    "    # Create new columns sequence list by adding other columns after selected column\n",
    "    new_column_order = columns + remaining_columns\n",
    "\n",
    "    # Now reassign this list of columns to dataframe\n",
    "    organized_df = df_with_consecutive_sequences.reindex(columns=new_column_order)\n",
    "\n",
    "    # Eradicate 'count' column\n",
    "    if 'count' in organized_df.columns:\n",
    "        organized_df.drop('count', axis=1, inplace=True)    \n",
    "    \n",
    "#     organized_df = df_with_consecutive_sequences[columns]\n",
    "    \n",
    "      # Sort uniqID, Day_Type, sequence by Ascending order \n",
    "    sorted_df = organized_df.sort_values(\n",
    "        by=['uniqID', 'Day_Type', 'sequence'], \n",
    "        ascending=[True, True, True]\n",
    "    )  \n",
    "    \n",
    "    sorted_df.reset_index(drop = True, inplace = True)\n",
    "    \n",
    "    \n",
    "        \n",
    "    tqdm.pandas(desc=\" - 4.6. drop consecutive homes except start and end\") \n",
    "    \n",
    "    # If there are duplicate Home trips -> delete second one\n",
    "    def drop_consecutive_homes(group):\n",
    "        homes = group['TRPPURP'] == 'Home'\n",
    "        consecutive = homes & homes.shift(fill_value=False)\n",
    "        drop_indices = consecutive[consecutive].index\n",
    "        return group.drop(drop_indices)\n",
    "\n",
    "    if print_progress == True:\n",
    "        droped_consecutive_homes_df = sorted_df.groupby(['uniqID', 'Day_Type']).progress_apply(drop_consecutive_homes).reset_index(drop=True)\n",
    "    else:\n",
    "        droped_consecutive_homes_df = sorted_df.groupby(['uniqID', 'Day_Type']).apply(drop_consecutive_homes).reset_index(drop=True)\n",
    "\n",
    "    # Reassign sequence\n",
    "    \n",
    "    \n",
    "    tqdm.pandas(desc=\" - 4.7. reassign sequence\") \n",
    "    def reset_sequence(group):\n",
    "        group['sequence'] = range(1, len(group) + 1)\n",
    "        return group\n",
    "\n",
    "    if print_progress == True:\n",
    "        reassigned_sequence_df = droped_consecutive_homes_df.groupby(['uniqID', 'Day_Type']).progress_apply(reset_sequence).reset_index(drop=True)\n",
    "    else:\n",
    "        reassigned_sequence_df = droped_consecutive_homes_df.groupby(['uniqID', 'Day_Type']).apply(reset_sequence).reset_index(drop=True)\n",
    "    \n",
    "    #------------------------------- fix errors\n",
    "    \n",
    "    tqdm.pandas(desc=\" - 4.8. fix home error if need ... (1)\") \n",
    "    \n",
    "    # Add new row if the last TRPPURP is not a 'Home' in each group\n",
    "    def add_home_row_if_needed(group):\n",
    "        if group['TRPPURP'].iloc[-1] != 'Home':\n",
    "            new_row = group.iloc[-1].copy()\n",
    "            new_row['TRPPURP'] = 'Home'\n",
    "            new_row['sequence'] = new_row['sequence'] + 1\n",
    "            group = pd.concat([group, pd.DataFrame([new_row])])\n",
    "        return group\n",
    "\n",
    "    if print_progress == True:    \n",
    "        fix_1_df = reassigned_sequence_df.groupby(['uniqID', 'Day_Type']).progress_apply(add_home_row_if_needed).reset_index(drop=True)\n",
    "    else:\n",
    "        fix_1_df = reassigned_sequence_df.groupby(['uniqID', 'Day_Type']).apply(add_home_row_if_needed).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    tqdm.pandas(desc=\" - 4.9. fix home error if need ... (2)\") \n",
    "    \n",
    "    def add_home_to_start_if_needed(group):\n",
    "        if group['TRPPURP'].iloc[0] != 'Home':\n",
    "            new_row = group.iloc[0].copy()\n",
    "            new_row['TRPPURP'] = 'Home'\n",
    "            new_row['sequence'] = 1\n",
    "            group = pd.concat([new_row.to_frame().T, group])\n",
    "            group['sequence'] = group['sequence'].astype(int) + 1\n",
    "            group['sequence'].iloc[0] = 1\n",
    "        return group\n",
    "\n",
    "    if print_progress == True:        \n",
    "        fix_2_df = fix_1_df.groupby(['uniqID', 'Day_Type']).progress_apply(add_home_to_start_if_needed).reset_index(drop=True)\n",
    "    else:\n",
    "        fix_2_df = fix_1_df.groupby(['uniqID', 'Day_Type']).apply(add_home_to_start_if_needed).reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    return fix_2_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Trip Timing Estimator\n",
    "### 3.0. preprocessing (1): Extracting dwell time by trip purpose using NHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dwellTime_listFromNHTS(df):\n",
    "    \"\"\"\n",
    "    Extracts and organizes dwell time distributions by trip count, trip purpose, and other classifications from NHTS data. \n",
    "    This function is intended to run once to prepare the data for further simulation.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing NHTS trip data.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary with dwell time lists categorized by age class, day type, trip count class, and trip purpose.\n",
    "    \"\"\"\n",
    "    # 1. Calculate trip count: Count the number of trips for each unique ID and day type.\n",
    "    trippub = df.copy()\n",
    "    grouped = trippub.groupby(['uniqID', 'Day_Type'])\n",
    "    trippub['tripCount'] = grouped['Trip_pur'].transform('count')  # Add trip count for each row based on grouping.\n",
    "\n",
    "    # 2. Create trip count class: Classify trip counts into three categories based on the number of trips per day.\n",
    "    # Categories are defined as 1-3 trips, 4-5 trips, and 6 or more trips, considering trips start and end at home.\n",
    "    trippub['tripCount_class'] = pd.cut(trippub['tripCount'], bins=[0, 4, 6, float('inf')], labels=[1, 2, 3], right=False)\n",
    "    # The bins parameter defines the range of trip counts for each class: \n",
    "    # - Class 1 for 1-3 trips (inclusive of starting and ending at home)\n",
    "    # - Class 2 for 4-5 trips\n",
    "    # - Class 3 for 6 or more trips.\n",
    "    # These classifications help in understanding the distribution of trip counts and corresponding dwell times.\n",
    "\n",
    "    dwellTime_dict = trippub.groupby(['age_class', 'Day_Type', 'tripCount_class', 'Trip_pur'])['Dwell_T_min'].apply(list).to_dict()\n",
    "    \n",
    "    return dwellTime_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0. preprocessing (2): Extracting trip start time by trip purpose using NHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startTime_listFromNHTS(df):\n",
    "    \"\"\"\n",
    "    Generates a dictionary mapping the start times of trips based on age class, day type, and the second trip purpose from the NHTS data.\n",
    "    This function groups the data and extracts start times to understand typical trip start patterns. \n",
    "    It's designed to be run once and reused for analysis or simulation purposes.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing NHTS trip data.\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary where each key is a tuple of (age class, day type, trip purpose) and each value is a list of \n",
    "      non-zero start times (in minutes from midnight) for that combination.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize an empty dictionary to store start times\n",
    "    startTime_dict = {}\n",
    "    trippub_new = df.copy()\n",
    "\n",
    "    # Group the data by unique ID, age class, and day type. This aggregation is suited for analysis on how \n",
    "    # start times may vary across different demographics and types of days (e.g., weekdays vs. weekends).\n",
    "    grouped_trippub = trippub_new.groupby(['uniqID', 'age_class', 'Day_Type'])\n",
    "\n",
    "    # Iterate through each group to collect start times\n",
    "    for (_, age_class, day_type), group in tqdm(grouped_trippub, desc='Make dict of starting time derived from NHTS data'):\n",
    "        # Only consider groups with more than one trip to ensure we're looking at subsequent trips\n",
    "        if len(group) > 1:\n",
    "            # Extract the trip purpose of the second trip in the sequence. This choice focuses on the start time \n",
    "            # of the day's first major trip after potentially leaving home.\n",
    "            trip_pur = group['Trip_pur'].iloc[1]\n",
    "            key = (age_class, day_type, trip_pur)  # Define a unique key for the dictionary\n",
    "\n",
    "            # Initialize the list in the dictionary if the key doesn't exist\n",
    "            if key not in startTime_dict:\n",
    "                startTime_dict[key] = []\n",
    "\n",
    "            # Add non-zero start times to the list for this key. Zero values are excluded to avoid considering \n",
    "            # trips that might not represent actual departures (e.g., midnight or incorrectly recorded times).\n",
    "            non_zero_values = [value for value in group['sta_T_min'].tolist() if value != 0]\n",
    "            startTime_dict[key].extend(non_zero_values)\n",
    "        \n",
    "    return startTime_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1) Estimating dwell time\n",
    "### 3.2) Estimating trip start time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignDwellStartT(df, dwellTime_dict, startTime_dict, print_progress=True):\n",
    "    \"\"\"\n",
    "    Estimates and assigns dwell times and start times for simulated trip data using distributions derived from NHTS data.\n",
    "    It first classifies each trip within the simulated data by trip count and then assigns dwell times based on\n",
    "    age class, day type, trip count class, and trip purpose. Finally, it assigns start times to the trips using\n",
    "    similar criteria.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the simulated trip data.\n",
    "    - dwellTime_dict: Dictionary containing dwell time distributions from NHTS data.\n",
    "    - startTime_dict: Dictionary containing start time distributions from NHTS data.\n",
    "    - print_progress: Boolean flag to print progress messages.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with 'Dwell_Time' and 'sta_T_min' (start time in minutes from midnight) assigned for each trip.\n",
    "    \"\"\"\n",
    "    \n",
    "    if print_progress == True:\n",
    "        print('<Trip timing estimator>')\n",
    "    \n",
    "    # Function to assign dwell time to each trip based on the dwellTime_dict distributions\n",
    "    def assignDwellTime(df, dwellTime_dict, print_progress):\n",
    "        simul_trip_sequence = df.copy()\n",
    "\n",
    "        tqdm.pandas(desc=\"1. classify tripCount of simulated data\")\n",
    "\n",
    "        # Classify and assign trip count class to each trip based on the size of each group (unique ID and day type)\n",
    "        group_counts = simul_trip_sequence.groupby(['uniqID', 'Day_Type']).size().to_dict()\n",
    "\n",
    "        def assign_class(row):\n",
    "            group_size = group_counts[(row['uniqID'], row['Day_Type'])]\n",
    "\n",
    "            if group_size <= 3:\n",
    "                return 1\n",
    "            elif 4 <= group_size <= 5:\n",
    "                return 2\n",
    "            else:\n",
    "                return 3\n",
    "\n",
    "        # Assign dwell time to each trip by randomly selecting from the corresponding distribution in dwellTime_dict\n",
    "        if print_progress == True:\n",
    "            simul_trip_sequence['trip_count_class'] = simul_trip_sequence.progress_apply(assign_class, axis=1)\n",
    "        else:\n",
    "            simul_trip_sequence['trip_count_class'] = simul_trip_sequence.apply(assign_class, axis=1)\n",
    "\n",
    "\n",
    "        # 2. Sampling Dwell_Time from distribution\n",
    "        tqdm.pandas(desc=\"2. Assign Dwell time\")\n",
    "\n",
    "        def assign_dwell_time(row):\n",
    "            # Convert day type to 'Weekday' or 'Weekend' for consistency with the dictionary keys\n",
    "            day_type_map = {\n",
    "                'Monday': 'Weekday',\n",
    "                'Tuesday': 'Weekday',\n",
    "                'Wednesday': 'Weekday',\n",
    "                'Thursday': 'Weekday',\n",
    "                'Friday': 'Weekday',\n",
    "                'Saturday': 'Weekend',\n",
    "                'Sunday': 'Weekend'\n",
    "            }\n",
    "            day_type = day_type_map[row['Day_Type']]\n",
    "\n",
    "            # Construct the key for the dictionary lookup\n",
    "            key = (row['ageGroup'], day_type, row['trip_count_class'], row['TRPPURP'])\n",
    "            dwell_times = dwellTime_dict.get(key, [0])\n",
    "\n",
    "            if not isinstance(dwell_times, (list, np.ndarray)) or len(dwell_times) == 0:\n",
    "                dwell_time_sample = np.random.randint(10, 301)\n",
    "                print(f\"cannot find from dic, put random dwelltime...({row['ageGroup']}, {row['Day_Type']}, {row['trip_count_class']}, {row['TRPPURP']}, value: {dwell_time_sample})\")\n",
    "                return dwell_time_sample\n",
    "\n",
    "            dwell_time_sample = -1\n",
    "            while dwell_time_sample < 0:\n",
    "                dwell_time_sample = np.random.choice(dwell_times)\n",
    "\n",
    "            return dwell_time_sample\n",
    "        \n",
    "        # Apply function to assign dwell time to each trip\n",
    "        if print_progress == True:\n",
    "            simul_trip_sequence['Dwell_Time'] = simul_trip_sequence.progress_apply(assign_dwell_time, axis=1)\n",
    "        else:\n",
    "            simul_trip_sequence['Dwell_Time'] = simul_trip_sequence.apply(assign_dwell_time, axis=1)\n",
    "\n",
    "        # drop column seq_NHTS\n",
    "        if 'seq_NHTS' in simul_trip_sequence.columns:\n",
    "            simul_trip_sequence = simul_trip_sequence.drop('seq_NHTS', axis=1)\n",
    "\n",
    "\n",
    "        return simul_trip_sequence\n",
    "    \n",
    "    # Apply the function to assign dwell times\n",
    "    dwell_table = assignDwellTime(df, dwellTime_dict, print_progress)\n",
    "    \n",
    "    # Function to assign start times to each trip\n",
    "    def assignStartTime(df, startTime_dict, print_progress):\n",
    "\n",
    "        simul_trip_sequence_dwell_time = df.copy()\n",
    "        simul_trip_sequence_dwell_time['sta_T_min'] = np.nan\n",
    "\n",
    "        tqdm.pandas(desc=\"3. Assign start time\")\n",
    "\n",
    "        # Function to assign start times within each group\n",
    "        def assign_sta_T_min(group):\n",
    "            if len(group) >= 2:\n",
    "                # Set the start time of the first trip to 0 (midnight)\n",
    "                first_row = group.iloc[0]\n",
    "                group.at[first_row.name, 'sta_T_min'] = 0\n",
    "\n",
    "                # Assign start time to the second trip based on startTime_dict\n",
    "                second_row = group.iloc[1]\n",
    "                key = (second_row['ageGroup'], second_row['Week_Type'], group['TRPPURP'].iloc[1])\n",
    "                if key in startTime_dict:\n",
    "                    group.at[second_row.name, 'sta_T_min'] = np.random.choice(startTime_dict[key])\n",
    "            else: \n",
    "                # For groups with only one trip, assign a start time of 0\n",
    "                first_row = group.iloc[0]\n",
    "                group.at[first_row.name, 'sta_T_min'] = 0\n",
    "\n",
    "            return group\n",
    "\n",
    "\n",
    "        if print_progress == True:\n",
    "            # Apply 'assign_sta_T_min' to each group of trips by unique ID and day type\n",
    "            simul_trip_sequence_2_start_time = simul_trip_sequence_dwell_time.groupby(['uniqID', 'Day_Type']).progress_apply(assign_sta_T_min)\n",
    "        else:\n",
    "            simul_trip_sequence_2_start_time = simul_trip_sequence_dwell_time.groupby(['uniqID', 'Day_Type']).apply(assign_sta_T_min)\n",
    "            \n",
    "        simul_trip_sequence_2_start_time.drop(columns=['Week_Type'], inplace=True)  # 임시로 만든 Week_Type 컬럼 삭제\n",
    "\n",
    "        return simul_trip_sequence_2_start_time\n",
    "    \n",
    "    # Assign start times to the trips with previously assigned dwell times\n",
    "    result_table = assignStartTime(dwell_table, startTime_dict, print_progress)\n",
    "    \n",
    "    return result_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Trip Mode Assigner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_tripMode(df, trip_mode_origin, print_progress=True):\n",
    "    \"\"\"\n",
    "    Assigns a travel mode to each trip in the simulated dataset based on the mode distribution from original data,\n",
    "    considering the age group and trip purpose. It also adjusts the assigned trip modes to reflect realistic travel patterns,\n",
    "    such as ensuring round trips have consistent modes and modifying modes based on trip sequence.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing the simulated trip data.\n",
    "    - trip_mode_origin: DataFrame with the original distribution of trip modes by age class and trip purpose.\n",
    "    - print_progress: Boolean indicating whether to display progress during the execution.\n",
    "\n",
    "    Returns:\n",
    "    - A DataFrame with an assigned 'Trip_mode' for each trip, adjusted for realism based on trip sequences.\n",
    "    \"\"\"\n",
    "    \n",
    "    if print_progress == True:\n",
    "        print(\"<Trip mode assigner>\")\n",
    "        \n",
    "    tqdm.pandas(desc=\"1. Assign initial trip modes\")\n",
    "    \n",
    "    # Convert the original trip mode distributions into a dictionary for efficient lookup\n",
    "    probability_dict = trip_mode_origin.set_index(['age_class', 'Trip_pur', 'Trip_mode'])['Trip_modeP'].to_dict()\n",
    "\n",
    "    def assign_trip_mode(row):\n",
    "        \"\"\"\n",
    "        Samples a trip mode based on the distribution for the given age group and trip purpose.\n",
    "        \"\"\"\n",
    "        age = row['ageGroup']\n",
    "        purpose = row['TRPPURP']\n",
    "\n",
    "        # Extract mode probabilities for the given age and purpose, defaulting to 0 if not found\n",
    "        mode_probabilities = {mode: probability_dict.get((age, purpose, mode), 0) for mode in trip_mode_origin['Trip_mode'].unique()}\n",
    "\n",
    "        # Sample a mode based on the probabilities\n",
    "        return np.random.choice(list(mode_probabilities.keys()), p=list(mode_probabilities.values()))\n",
    "\n",
    "    if print_progress == True:\n",
    "        df['Trip_mode'] = df.progress_apply(assign_trip_mode, axis=1)\n",
    "    else:\n",
    "        df['Trip_mode'] = df.apply(assign_trip_mode, axis=1)\n",
    "    \n",
    "    tqdm.pandas(desc=\"2. Modify Trip_mode based on the first row of each group\")\n",
    "\n",
    "    def modify_trip_mode(group):        \n",
    "        \"\"\"\n",
    "        Modifies the trip mode of the first trip in each group if its purpose is not 'Home',\n",
    "        since the mode for trips starting from 'Home' might follow a different pattern.\n",
    "        \"\"\"\n",
    "        \n",
    "        first_row = group.iloc[0]\n",
    "        if first_row['TRPPURP'] == 'Home':\n",
    "            group.at[first_row.name, 'Trip_mode'] = np.nan # Clear the mode if the first trip starts from 'Home'\n",
    "        else:\n",
    "            print(first_row['uniqID'], first_row['Day_Type'], 'Ah uh') # Log if the first trip doesn't start from 'Home'\n",
    "        return group\n",
    "\n",
    "    # Apply mode modification to each group of trips\n",
    "    if print_progress == True:\n",
    "        put_trip_mode_df = df.groupby(['uniqID', 'Day_Type']).progress_apply(modify_trip_mode)\n",
    "    else:\n",
    "        put_trip_mode_df = df.groupby(['uniqID', 'Day_Type']).apply(modify_trip_mode)\n",
    "    \n",
    "    \n",
    "    def adjust_trip_mode_for_car(df):\n",
    "        \"\"\"\n",
    "        Adjusts the trip mode to 'Car' for the last trip if the first trip mode is 'Car',\n",
    "        reflecting the assumption that round trips typically use the same mode.\n",
    "        It also checks for consistency in modes for intermediate trips.\n",
    "        \"\"\"\n",
    "    \n",
    "        tqdm.pandas(desc=\"3. Adjust Trip_mode for round / one-way trip\")\n",
    "    \n",
    "        def process_group(group):\n",
    "            if len(group) == 1:\n",
    "                return group # No adjustment needed for single-trip groups\n",
    "\n",
    "            if group['Trip_mode'].iloc[1] != 'Car':\n",
    "                return group # No adjustment if the first trip mode isn't 'Car'\n",
    "\n",
    "            # 첫 Trip_mode가 Car라면 마지막 Trip_mode를 Car로 설정\n",
    "            group['Trip_mode'].iloc[-1] = 'Car'\n",
    "\n",
    "            # Set the last trip mode to 'Car' if the first is 'Car'\n",
    "            current_mode = 'Car'\n",
    "            for idx in range(2, len(group) - 1):\n",
    "                if group['Trip_mode'].iloc[idx] != current_mode:\n",
    "                    # Check for round trips and adjust modes accordingly\n",
    "                    next_indices = range(idx+1, len(group))\n",
    "                    if group['TRPPURP'].iloc[idx-1] in [group['TRPPURP'].iloc[next_idx] for next_idx in next_indices]:\n",
    "                        current_mode = group['Trip_mode'].iloc[idx]\n",
    "                    else:\n",
    "                        # Adjust mode for one-way trips\n",
    "                        group['Trip_mode'].iloc[idx] = current_mode\n",
    "\n",
    "            return group\n",
    "        \n",
    "        # Apply the adjustment to all groups\n",
    "        if print_progress == True:\n",
    "            df = df.groupby(['uniqID', 'Day_Type']).progress_apply(process_group).reset_index(drop=True)\n",
    "        else:\n",
    "            df = df.groupby(['uniqID', 'Day_Type']).apply(process_group).reset_index(drop=True)\n",
    "        return df\n",
    "\n",
    "    adjust_trip_mode_df = adjust_trip_mode_for_car(put_trip_mode_df)\n",
    "    \n",
    "    return adjust_trip_mode_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Spatial Trip Route Estimator\n",
    "### 5.0. preprocessing: ratio between straight path and network path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Estimate probabilistic destinations for trip purpose t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Compute trip distance and duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Optimize Trips with Logical and space-time constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execusion by User"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Trip Occurence Builder\n",
    "### 1.1. The probability of a person with age ‘a’ having ‘t’ trips occurs in a single day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. The number of trips occurring ‘k’ times for a single individual ‘i’ in a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Trip Chains Builder\n",
    "### 2.0. preprocessing: Create trip seqeunce using origin NHTS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Finding optimal origin sequence O_i most similar to S_i\n",
    "### 2.2) Randomly assign the trip sequence for S_i\n",
    "### 2.3) Reassign the sequence of trip in S_i based on O_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Trip Timing Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Trip Mode Assigner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Spatial Trip Route Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
